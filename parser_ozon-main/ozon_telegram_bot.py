import asyncio
import logging
import pandas as pd
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
import json
import re
import random
from urllib.parse import quote
from playwright.async_api import async_playwright
import os
from datetime import datetime
import tempfile
import signal
import sys

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s"
)
logger = logging.getLogger("ozon_telegram_bot")
TELEGRAM_BOT_TOKEN = "7572687386:AAEfd9tIcg5jpfXJYBxy-06XE1jvliInbV4"
MAX_PRODUCTS = 15
PAGES_TO_PARSE = 2
application = None
user_states = {}


class OzonParser:
    def __init__(self):
        self.playwright = None
        self.browser = None
        self.page = None

    async def human_delay(self, min_sec=1, max_sec=3):
        await asyncio.sleep(random.uniform(min_sec, max_sec))

    async def setup_browser(self):
        self.playwright = await async_playwright().start()
        self.browser = await self.playwright.chromium.launch(
            headless=True,
            args=[
                "--disable-blink-features=AutomationControlled",
                "--disable-dev-shm-usage",
                "--no-sandbox",
                "--disable-web-security",
                "--disable-features=VizDisplayCompositor"
            ],
            slow_mo=50
        )

        self.context = await self.browser.new_context(
            viewport={"width": 1920, "height": 1080},
            user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            java_script_enabled=True,
            ignore_https_errors=True
        )

        await self.context.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', { get: () => undefined });
            Object.defineProperty(navigator, 'plugins', { get: () => [1, 2, 3, 4, 5] });
        """)

        self.page = await self.context.new_page()
        self.page.set_default_timeout(15000)
        self.page.set_default_navigation_timeout(20000)

    async def close_browser(self):
        if self.browser:
            await self.browser.close()
        if self.playwright:
            await self.playwright.stop()

    async def fetch_product_links(self, query, pages=2):
        try:
            encoded_query = quote(query)
            search_url = f"https://www.ozon.ru/search/?text={encoded_query}&from_global=true"

            logger.info(f"–ü–æ–∏—Å–∫: {query}")
            await self.page.goto(search_url, wait_until="domcontentloaded", timeout=15000)
            await self.human_delay(2, 3)

            current_url = self.page.url
            if "category" in current_url and "text" not in current_url:
                logger.warning("–ü–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—é")
                search_url = f"https://www.ozon.ru/search/?text={encoded_query}"
                await self.page.goto(search_url, wait_until="domcontentloaded", timeout=15000)
                await self.human_delay(2, 3)

            selectors_to_wait = [
                "[data-widget='searchResults']",
                ".widget-search-result-container",
                ".search-container",
                ".tile-root",
                "div[data-widget*='search']",
                ".a0c6"
            ]

            for selector in selectors_to_wait:
                try:
                    await self.page.wait_for_selector(selector, timeout=5000)
                    break
                except:
                    continue

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
            return []

        links = set()
        for p in range(1, pages + 1):
            logger.info(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {p}/{pages}")

            try:
                await self.page.wait_for_selector("a[href*='/product/']", timeout=10000)

                product_selectors = [
                    "a[href*='/product/']",
                    ".tile-root a[href*='/product/']",
                    "[data-widget*='searchResults'] a[href*='/product/']",
                    "div a[href*='/product/']"
                ]

                elements = []
                for selector in product_selectors:
                    found_elements = await self.page.query_selector_all(selector)
                    elements.extend(found_elements)
                    if found_elements:
                        break

                seen_hrefs = set()
                unique_elements = []
                for e in elements:
                    href = await e.get_attribute("href")
                    if href and href not in seen_hrefs:
                        seen_hrefs.add(href)
                        unique_elements.append(e)

                elements = unique_elements

                for e in elements:
                    href = await e.get_attribute("href")
                    if href and "/product/" in href:
                        full_url = "https://www.ozon.ru" + href.split("?")[0] if href.startswith("/") else href
                        if "product" in full_url.lower() and len(full_url) > 30:
                            links.add(full_url)

                logger.info(f"–ù–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫: {len(links)}")

                if p < pages:
                    next_selectors = [
                        "a[aria-label*='–°–ª–µ–¥—É—é—â–∞—è']",
                        "a[data-widget*='paginator-next']",
                        "[data-widget='paginator'] a:last-child",
                        ".paginator .next",
                        "a:has-text('–î–∞–ª–µ–µ')",
                    ]

                    next_btn = None
                    for selector in next_selectors:
                        next_btn = await self.page.query_selector(selector)
                        if next_btn:
                            break

                    if not next_btn:
                        break

                    await next_btn.scroll_into_view_if_needed()
                    await self.human_delay(1, 2)
                    await next_btn.click()
                    await self.human_delay(3, 4)

            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {p}: {e}")
                continue

        filtered_links = [link for link in links if "ozon.ru" in link and "/product/" in link]
        logger.info(f"–í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(filtered_links)}")
        return filtered_links

    async def parse_price(self, content):
        price = None

        try:
            json_patterns = [
                r'window\.__INITIAL_STATE__\s*=\s*({.*?});',
                r'<script[^>]*data-widget[^>]*>([^<]*)</script>',
            ]

            for pattern in json_patterns:
                matches = re.findall(pattern, content, re.DOTALL)
                for match in matches:
                    try:
                        if isinstance(match, str) and match.startswith('{'):
                            data = json.loads(match)

                            def find_price(obj):
                                if isinstance(obj, dict):
                                    for key, value in obj.items():
                                        if key in ['price', 'currentPrice', 'finalPrice', 'amount'] and value:
                                            if isinstance(value, (int, float)):
                                                return int(value)
                                            elif isinstance(value, str) and value.isdigit():
                                                return int(value)
                                        if isinstance(value, (dict, list)):
                                            result = find_price(value)
                                            if result:
                                                return result
                                elif isinstance(obj, list):
                                    for item in obj:
                                        result = find_price(item)
                                        if result:
                                            return result
                                return None

                            found_price = find_price(data)
                            if found_price:
                                price = found_price
                                break

                    except:
                        continue

            if not price:
                price_selectors = [
                    "[data-widget='webPrice']",
                    "[data-widget='price']",
                    ".price",
                    "[class*='price']",
                    ".c3118",
                    ".yo3",
                ]

                for selector in price_selectors:
                    try:
                        price_elem = await self.page.query_selector(selector)
                        if price_elem:
                            price_text = await price_elem.text_content()
                            if price_text:
                                price_match = re.search(r'(\d[\d\s]*)\s*[‚ÇΩ—Ä—Ä—É–±RUB]', price_text.replace(',', ''))
                                if price_match:
                                    price_str = price_match.group(1).replace(' ', '').replace('\u2009', '').replace(
                                        '\xa0', '')
                                    if price_str.isdigit():
                                        price = int(price_str)
                                        break
                    except:
                        continue

        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ü–µ–Ω—ã: {e}")

        return price

    async def parse_rating_and_reviews(self):
        """–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Ä–µ–π—Ç–∏–Ω–≥–∞ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ—Ç–∑—ã–≤–æ–≤ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º–∏ Ozon"""
        rating = None
        reviews = None

        try:
            await self.human_delay(2, 3)
            rating_selectors = [
                "span[data-widget='webReviewRating']",
                "div[data-widget='webReviewRating']",
                "[class*='rating']",
                "[class*='Rating']",
                ".a0c8",
                ".a2a0",
                "div > span:has-text('‚ÇΩ') + div span",
                "text=‚ÇΩ >> xpath=following::span[contains(., '.')]",
            ]

            reviews_selectors = [
                "span[data-widget='webReviewCount']",
                "a[href*='reviews'] span",
                "[class*='review-count']",
                "[class*='reviewCount']",
                ".a0c9",
                ".a2a1",
                "text=‚ÇΩ >> xpath=following::a[contains(@href, 'reviews')]",
            ]
            for selector in rating_selectors:
                try:
                    rating_elem = await self.page.query_selector(selector)
                    if rating_elem:
                        rating_text = await rating_elem.text_content()
                        if rating_text:
                            logger.info(f"–ù–∞–π–¥–µ–Ω —Ç–µ–∫—Å—Ç —Ä–µ–π—Ç–∏–Ω–≥–∞: '{rating_text}'")
                            rating_match = re.search(r'(\d+\.\d+|\d+)', rating_text.replace(',', '.'))
                            if rating_match:
                                rating_val = rating_match.group(1)
                                try:
                                    rating = float(rating_val)
                                    logger.info(f"–ù–∞–π–¥–µ–Ω —Ä–µ–π—Ç–∏–Ω–≥ —á–µ—Ä–µ–∑ —Å–µ–ª–µ–∫—Ç–æ—Ä {selector}: {rating}")
                                    break
                                except ValueError:
                                    continue
                except Exception as e:
                    continue

            if rating is None:
                try:
                    content = await self.page.content()
                    rating_patterns = [
                        r'"rating":\s*["]?(\d+\.\d+|\d+)["]?',
                        r'"ratingValue":\s*["]?(\d+\.\d+|\d+)["]?',
                        r'"averageRating":\s*["]?(\d+\.\d+|\d+)["]?',
                        r'—Ä–µ–π—Ç–∏–Ω–≥[^"]*?(\d+\.\d+|\d+)',
                        r'rating[^"]*?(\d+\.\d+|\d+)',
                    ]

                    for pattern in rating_patterns:
                        matches = re.findall(pattern, content, re.IGNORECASE)
                        for match in matches:
                            try:
                                rating_candidate = float(match)
                                if 1 <= rating_candidate <= 5:
                                    rating = rating_candidate
                                    logger.info(f"–ù–∞–π–¥–µ–Ω —Ä–µ–π—Ç–∏–Ω–≥ —á–µ—Ä–µ–∑ regex: {rating}")
                                    break
                            except ValueError:
                                continue
                        if rating:
                            break
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Ä–µ–π—Ç–∏–Ω–≥–∞ –≤ —Ç–µ–∫—Å—Ç–µ: {e}")
            for selector in reviews_selectors:
                try:
                    reviews_elem = await self.page.query_selector(selector)
                    if reviews_elem:
                        reviews_text = await reviews_elem.text_content()
                        if reviews_text:
                            logger.info(f"–ù–∞–π–¥–µ–Ω —Ç–µ–∫—Å—Ç –æ—Ç–∑—ã–≤–æ–≤: '{reviews_text}'")
                            patterns = [
                                r'(\d+[\d\s]*)\s*(–æ—Ç–∑—ã–≤|review)',
                                r'(\d+[\d\s]*)',
                            ]

                            for pattern in patterns:
                                reviews_match = re.search(pattern, reviews_text, re.IGNORECASE)
                                if reviews_match:
                                    reviews_str = reviews_match.group(1).replace(' ', '').replace('\u2009', '').replace(
                                        '\xa0', '')
                                    if reviews_str.isdigit():
                                        reviews = int(reviews_str)
                                        logger.info(f"–ù–∞–π–¥–µ–Ω—ã –æ—Ç–∑—ã–≤—ã —á–µ—Ä–µ–∑ —Å–µ–ª–µ–∫—Ç–æ—Ä {selector}: {reviews}")
                                        break
                except Exception as e:
                    continue
            if reviews is None:
                try:
                    content = await self.page.content()
                    reviews_patterns = [
                        r'"reviewCount":\s*["]?(\d+)["]?',
                        r'"reviewsCount":\s*["]?(\d+)["]?',
                        r'"review_count":\s*["]?(\d+)["]?',
                        r'–æ—Ç–∑—ã–≤[–æ–≤]*[^"]*?(\d+)',
                        r'review[s]*[^"]*?(\d+)',
                    ]

                    for pattern in reviews_patterns:
                        matches = re.findall(pattern, content, re.IGNORECASE)
                        for match in matches:
                            if match.isdigit():
                                reviews_candidate = int(match)
                                if reviews_candidate > 0:
                                    reviews = reviews_candidate
                                    logger.info(f"–ù–∞–π–¥–µ–Ω—ã –æ—Ç–∑—ã–≤—ã —á–µ—Ä–µ–∑ regex: {reviews}")
                                    break
                        if reviews:
                            break
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –æ—Ç–∑—ã–≤–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ: {e}")
            if rating is None:
                try:
                    possible_rating_elements = await self.page.query_selector_all("span, div, button")
                    for elem in possible_rating_elements:
                        try:
                            text = await elem.text_content()
                            if text:
                                rating_match = re.search(r'^\d+\.\d+$', text.strip())
                                if rating_match:
                                    rating = float(rating_match.group())
                                    logger.info(f"–ù–∞–π–¥–µ–Ω —Ä–µ–π—Ç–∏–Ω–≥ –ø–æ —Ñ–æ—Ä–º–∞—Ç—É: {rating}")
                                    break
                        except:
                            continue
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–º –ø–æ–∏—Å–∫–µ —Ä–µ–π—Ç–∏–Ω–≥–∞: {e}")

        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ä–µ–π—Ç–∏–Ω–≥–∞ –∏ –æ—Ç–∑—ã–≤–æ–≤: {e}")

        return rating, reviews

    async def parse_product(self, url):
        try:
            logger.info(f"–ü–∞—Ä—Å–∏–º —Ç–æ–≤–∞—Ä: {url}")
            await self.page.goto(url, wait_until="domcontentloaded", timeout=20000)
            await self.human_delay(2, 3)
            try:
                await self.page.wait_for_selector("h1", timeout=10000)
            except:
                logger.warning(f"–∑–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω: {url}")

            content = await self.page.content()
            title_elem = await self.page.query_selector("h1")
            title = await title_elem.text_content() if title_elem else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"

            price = await self.parse_price(content)
            rating, reviews = await self.parse_rating_and_reviews()
            formatted_price = f"{price} ‚ÇΩ" if price is not None else None

            logger.info(
                f"–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞: {title[:30]}... | –¶–µ–Ω–∞: {formatted_price} | –†–µ–π—Ç–∏–Ω–≥: {rating} | –û—Ç–∑—ã–≤—ã: {reviews}")

            return {
                "–ù–∞–∑–≤–∞–Ω–∏–µ": title.strip(),
                "–¶–µ–Ω–∞": formatted_price,
                "–†–µ–π—Ç–∏–Ω–≥": rating,
                "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤": reviews,
                "–°—Å—ã–ª–∫–∞": url
            }

        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {url}: {e}")
            return {
                "–ù–∞–∑–≤–∞–Ω–∏–µ": "–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞",
                "–¶–µ–Ω–∞": None,
                "–†–µ–π—Ç–∏–Ω–≥": None,
                "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤": None,
                "–°—Å—ã–ª–∫–∞": url
            }

    async def search_products(self, query, pages=2, max_products=15):
        try:
            await self.setup_browser()
            links = await self.fetch_product_links(query, pages)

            if not links:
                return None, "–Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É"

            results = []
            max_products = min(max_products, len(links))

            for i, url in enumerate(links[:max_products], 1):
                logger.info(f"[{i}/{max_products}] –ü–∞—Ä—Å–∏–º —Ç–æ–≤–∞—Ä")
                product = await self.parse_product(url)
                results.append(product)

                if i < max_products:
                    await self.human_delay(1, 2)

            df = pd.DataFrame(results)

            total = len(df)
            with_prices = df['–¶–µ–Ω–∞'].notna().sum()
            with_ratings = df['–†–µ–π—Ç–∏–Ω–≥'].notna().sum()
            with_reviews = df['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤'].notna().sum()

            stats_message = (
                f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞:\n"
                f"‚Ä¢ –í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤: {total}\n"
                f"‚Ä¢ –° —Ü–µ–Ω–∞–º–∏: {with_prices}\n"
                f"‚Ä¢ –° —Ä–µ–π—Ç–∏–Ω–≥–∞–º–∏: {with_ratings}\n"
                f"‚Ä¢ –° –æ—Ç–∑—ã–≤–∞–º–∏: {with_reviews}\n"
                f"‚Ä¢ –ó–∞–ø—Ä–æ—Å: '{query}'"
            )

            return df, stats_message

        except Exception as e:
            logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
            return None, f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ: {str(e)}"
        finally:
            await self.close_browser()
ozon_parser = OzonParser()

async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    welcome_message = (
        "–ë–æ—Ç –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ç–æ–≤–∞—Ä–æ–≤ —Å Ozon.\n\n"
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ –∏–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—é, –Ω–∞–ø—Ä–∏–º–µ—Ä:\n"
        "‚Ä¢ '–Ω–æ—É—Ç–±—É–∫'\n"
        "‚Ä¢ '–∫—Ä–µ–º –¥–ª—è –ª–∏—Ü–∞'\n"
        "‚Ä¢ '–∏–≥—Ä–æ–≤–∞—è –º—ã—à—å'\n"
        "‚Ä¢ '—Ç–µ–ª–µ—Ñ–æ–Ω samsung'\n\n"
        "–Ø –Ω–∞–π–¥—É —Ç–æ–≤–∞—Ä—ã –∏ –ø—Ä–∏—à–ª—é –≤–∞–º CSV —Ñ–∞–π–ª —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏!\n\n"
        "**–≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö:**\n"
        "‚Ä¢ –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞\n"
        "‚Ä¢ –¶–µ–Ω–∞ –≤ —Ä—É–±–ª—è—Ö\n"
        "‚Ä¢ –†–µ–π—Ç–∏–Ω–≥ —Ç–æ–≤–∞—Ä–∞\n"
        "‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤\n"
        "‚Ä¢ –°—Å—ã–ª–∫–∞ –Ω–∞ —Ç–æ–≤–∞—Ä\n\n"
        "–ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–Ω–∏–º–∞–µ—Ç 1-3 –º–∏–Ω—É—Ç—ã..."
    )

    await update.message.reply_text(welcome_message)


async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_chat.id
    user_message = update.message.text.strip()

    if user_message.startswith('/'):
        return

    if len(user_message) < 2:
        await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –±–æ–ª–µ–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –∑–∞–ø—Ä–æ—Å (–º–∏–Ω–∏–º—É–º 2 —Å–∏–º–≤–æ–ª–∞)")
        return

    try:
        progress_message = await update.message.reply_text(
            f"–ò—â—É —Ç–æ–≤–∞—Ä—ã –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{user_message}'\n"
            f"–≠—Ç–æ –∑–∞–π–º–µ—Ç 1-3 –º–∏–Ω—É—Ç—ã..."
        )

        df, stats_message = await ozon_parser.search_products(
            query=user_message,
            pages=PAGES_TO_PARSE,
            max_products=MAX_PRODUCTS
        )

        if df is not None and len(df) > 0:
            with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False, encoding='utf-8-sig') as tmp_file:
                df.to_csv(tmp_file.name, index=False, encoding='utf-8-sig')
                tmp_filename = tmp_file.name

            try:
                await update.message.reply_text(stats_message)

                with open(tmp_filename, 'rb') as file:
                    await update.message.reply_document(
                        document=file,
                        filename=f"ozon_{user_message}_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                        caption=f"–§–∞–π–ª —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{user_message}'"
                    )

                top_products = df.head(3)
                preview_message = "—Ç–æ–ø 3 —Ç–æ–≤–∞—Ä–∞:\n\n"

                for i, (_, row) in enumerate(top_products.iterrows(), 1):
                    price_str = row['–¶–µ–Ω–∞'] if pd.notna(row['–¶–µ–Ω–∞']) else "–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞"
                    rating_str = f"{row['–†–µ–π—Ç–∏–Ω–≥']}" if pd.notna(row['–†–µ–π—Ç–∏–Ω–≥']) else " –ù–µ—Ç —Ä–µ–π—Ç–∏–Ω–≥–∞"
                    reviews_str = f"{row['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤']} –æ—Ç–∑—ã–≤–æ–≤" if pd.notna(
                        row['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤']) else "–ù–µ—Ç –æ—Ç–∑—ã–≤–æ–≤"

                    preview_message += (
                        f"{i}. {row['–ù–∞–∑–≤–∞–Ω–∏–µ'][:50]}...\n"
                        f"   {price_str} | {rating_str} | {reviews_str}\n\n"
                    )

                await update.message.reply_text(preview_message)

            finally:
                os.unlink(tmp_filename)

        else:
            await update.message.reply_text(stats_message)

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
        await update.message.reply_text("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")


async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    help_message = (
        "‚ÑπÔ∏è –ü–æ–º–æ—â—å –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –±–æ—Ç–∞:\n\n"
        "üîç **–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**\n"
        "1. –ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ –∏–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\n"
        "2. –ë–æ—Ç –Ω–∞–π–¥–µ—Ç —Ç–æ–≤–∞—Ä—ã –Ω–∞ Ozon\n"
        "3. –í—ã –ø–æ–ª—É—á–∏—Ç–µ CSV —Ñ–∞–π–ª —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏\n\n"
        "üìä **–ß—Ç–æ –≤—Ö–æ–¥–∏—Ç –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:**\n"
        "‚Ä¢ **–ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞** - –ø–æ–ª–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ\n"
        "‚Ä¢ **–¶–µ–Ω–∞** - –≤ —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö —Ä—É–±–ª—è—Ö (‚ÇΩ)\n"
        "‚Ä¢ **–†–µ–π—Ç–∏–Ω–≥** - –æ—Ü–µ–Ω–∫–∞ —Ç–æ–≤–∞—Ä–∞ –æ—Ç –ø–æ–∫—É–ø–∞—Ç–µ–ª–µ–π\n"
        "‚Ä¢ **–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤** - —Å–∫–æ–ª—å–∫–æ –æ—Ç–∑—ã–≤–æ–≤ –æ—Å—Ç–∞–≤–ª–µ–Ω–æ\n"
        "‚Ä¢ **–°—Å—ã–ª–∫–∞ –Ω–∞ —Ç–æ–≤–∞—Ä** - –ø—Ä—è–º–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ Ozon\n\n"
        "‚è±Ô∏è **–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:** 1-3 –º–∏–Ω—É—Ç—ã\n"
        "üì¶ **–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤:** –¥–æ 15\n\n"
        "üí° **–ü—Ä–∏–º–µ—Ä—ã –∑–∞–ø—Ä–æ—Å–æ–≤:**\n"
        "‚Ä¢ '–Ω–æ—É—Ç–±—É–∫ asus'\n"
        "‚Ä¢ '–∫—Ä–µ–º –¥–ª—è —Ä—É–∫'\n"
        "‚Ä¢ '—Å–º–∞—Ä—Ç—Ñ–æ–Ω'\n"
        "‚Ä¢ '–Ω–∞—É—à–Ω–∏–∫–∏ –±–µ—Å–ø—Ä–æ–≤–æ–¥–Ω—ã–µ'\n\n"
        "üí∞ **–¶–µ–Ω—ã –æ—Ç–æ–±—Ä–∞–∂–∞—é—Ç—Å—è –≤ —Ä—É–±–ª—è—Ö (‚ÇΩ)**"
    )

    await update.message.reply_text(help_message)


async def error_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    logger.error(f"–û—à–∏–±–∫–∞: {context.error}")


def signal_handler(sig, frame):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è graceful shutdown"""
    logger.info("–ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è...")
    if application:
        application.stop()
    sys.exit(0)


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ –±–æ—Ç–∞"""
    global application
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    try:
        application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
        application.add_handler(CommandHandler("start", start_command))
        application.add_handler(CommandHandler("help", help_command))
        application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
        application.add_error_handler(error_handler)
        logger.info("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω")
        application.run_polling()

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –±–æ—Ç–∞: {e}")
    finally:
        logger.info("–ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")


if __name__ == "__main__":
    main()