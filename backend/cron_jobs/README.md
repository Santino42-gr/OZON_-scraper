## Cron Jobs –¥–ª—è OZON Scraper

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏ –¥–ª—è —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã.

---

## üìã –°–ø–∏—Å–æ–∫ Cron Jobs

### 1. **Price History Collector** (`price_history_collector.py`)

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ:** –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Å–±–æ—Ä –∏—Å—Ç–æ—Ä–∏–∏ —Ü–µ–Ω —Ç–æ–≤–∞—Ä–æ–≤ OZON

**–†–∞—Å–ø–∏—Å–∞–Ω–∏–µ:** –ö–∞–∂–¥—ã–µ 24 —á–∞—Å–∞ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 03:00 –Ω–æ—á–∏)

**–ß—Ç–æ –¥–µ–ª–∞–µ—Ç:**
- –ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ –∞–∫—Ç–∏–≤–Ω—ã–µ –∞—Ä—Ç–∏–∫—É–ª—ã –∏–∑ –ë–î
- –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∞—Ä—Ç–∏–∫—É–ª–∞ –≤—ã–ø–æ–ª–Ω—è–µ—Ç web scraping —Ü–µ–Ω
- –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ —Ç–∞–±–ª–∏—Ü—É `ozon_scraper_price_history`
- –õ–æ–≥–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è

**–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:**
```bash
# .env
OZON_SCRAPER_BATCH_SIZE=10      # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞—Ä—Ç–∏–∫—É–ª–æ–≤ –≤ batch
OZON_SCRAPER_DELAY=5            # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ (—Å–µ–∫)
```

---

## üöÄ –ó–∞–ø—É—Å–∫

### –í—Ä—É—á–Ω—É—é (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)

```bash
cd backend
python -m cron_jobs.price_history_collector
```

### –ß–µ—Ä–µ–∑ Docker Compose

```bash
docker-compose up cron-worker
```

### –ß–µ—Ä–µ–∑ —Å–∏—Å—Ç–µ–º–Ω—ã–π Cron (Linux/Mac)

```bash
# –û—Ç–∫—Ä—ã—Ç—å crontab
crontab -e

# –î–æ–±–∞–≤–∏—Ç—å –∑–∞–¥–∞—á—É (–∫–∞–∂–¥—ã–π –¥–µ–Ω—å –≤ 03:00)
0 3 * * * cd /path/to/project/backend && python -m cron_jobs.price_history_collector >> /var/log/ozon_scraper_cron.log 2>&1
```

### –ß–µ—Ä–µ–∑ GitHub Actions (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

–°–æ–∑–¥–∞—Ç—å `.github/workflows/price_history_cron.yml`:

```yaml
name: Price History Collection

on:
  schedule:
    - cron: '0 3 * * *'  # –ö–∞–∂–¥—ã–π –¥–µ–Ω—å –≤ 03:00 UTC
  workflow_dispatch:      # –†—É—á–Ω–æ–π –∑–∞–ø—É—Å–∫

jobs:
  collect-prices:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          cd backend
          pip install -r requirements.txt
      
      - name: Run price history collector
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          OZON_SCRAPER_BATCH_SIZE: 10
          OZON_SCRAPER_DELAY: 5
        run: |
          cd backend
          python -m cron_jobs.price_history_collector
```

---

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

### –ü—Ä–æ—Å–º–æ—Ç—Ä –ª–æ–≥–æ–≤

```bash
# Docker logs
docker-compose logs -f cron-worker

# System logs
tail -f /var/log/ozon_scraper_cron.log
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤ –ë–î

```sql
-- –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 –∑–∞–ø—É—Å–∫–æ–≤ cron job
SELECT 
    timestamp,
    message,
    metadata->>'stats' as stats
FROM ozon_scraper_logs
WHERE event_type = 'cron_price_history_collection'
ORDER BY timestamp DESC
LIMIT 10;

-- Success rate –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π
SELECT 
    DATE(timestamp) as date,
    COUNT(*) as total_runs,
    AVG((metadata->'stats'->>'successful')::int) as avg_successful,
    AVG((metadata->'stats'->>'failed')::int) as avg_failed
FROM ozon_scraper_logs
WHERE event_type = 'cron_price_history_collection'
  AND timestamp >= NOW() - INTERVAL '7 days'
GROUP BY DATE(timestamp)
ORDER BY date DESC;
```

---

## ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è

### –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è

| Cron Job | –†–∞—Å–ø–∏—Å–∞–Ω–∏–µ | Cron Expression | –û–ø–∏—Å–∞–Ω–∏–µ |
|----------|-----------|-----------------|----------|
| Price History | –ö–∞–∂–¥—ã–π –¥–µ–Ω—å –≤ 03:00 | `0 3 * * *` | –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞ |
| Price History | –ö–∞–∂–¥—ã–µ 12 —á–∞—Å–æ–≤ | `0 */12 * * *` | –ë–æ–ª–µ–µ —á–∞—Å—Ç–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ |
| Price History | –ö–∞–∂–¥—ã–µ 6 —á–∞—Å–æ–≤ | `0 */6 * * *` | –î–ª—è –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ |

### –í—ã–±–æ—Ä –≤—Ä–µ–º–µ–Ω–∏

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**
- ‚úÖ 03:00 - 05:00 (–Ω–æ—á—å) - –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞ –Ω–∞ OZON
- ‚úÖ –ò–∑–±–µ–≥–∞–π—Ç–µ –ø–∏–∫–æ–≤—ã—Ö —á–∞—Å–æ–≤ (10:00 - 22:00)
- ‚úÖ –£—á–∏—Ç—ã–≤–∞–π—Ç–µ —á–∞—Å–æ–≤–æ–π –ø–æ—è—Å —Å–µ—Ä–≤–µ—Ä–∞

---

## üõ†Ô∏è –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ–≤—ã—Ö Cron Jobs

### Template –¥–ª—è –Ω–æ–≤–æ–≥–æ job

```python
"""
My Custom Cron Job

Description: What this job does
Schedule: When to run
"""

import asyncio
from loguru import logger
from database import get_supabase_client

class MyCustomJob:
    def __init__(self):
        self.supabase = get_supabase_client()
        self.stats = {"start_time": None, "end_time": None}
    
    async def run(self):
        logger.info("Starting My Custom Job...")
        try:
            # Your logic here
            pass
        except Exception as e:
            logger.error(f"Job failed: {e}")
        finally:
            self.log_execution()
    
    def log_execution(self):
        self.supabase.table("ozon_scraper_logs").insert({
            "level": "INFO",
            "event_type": "cron_my_custom_job",
            "message": "Job completed",
            "metadata": self.stats
        }).execute()

async def main():
    job = MyCustomJob()
    await job.run()

if __name__ == "__main__":
    asyncio.run(main())
```

---

## üêõ Troubleshooting

### –ü—Ä–æ–±–ª–µ–º–∞: Cron job –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è

**–†–µ—à–µ–Ω–∏–µ:**
1. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ª–æ–≥–∏: `docker-compose logs cron-worker`
2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
3. –£–±–µ–¥–∏—Ç—å—Å—è —á—Ç–æ –ë–î –¥–æ—Å—Ç—É–ø–Ω–∞

### –ü—Ä–æ–±–ª–µ–º–∞: –ú–Ω–æ–≥–æ –æ—à–∏–±–æ–∫ scraping (403, timeout)

**–†–µ—à–µ–Ω–∏–µ:**
1. –£–≤–µ–ª–∏—á–∏—Ç—å `OZON_SCRAPER_DELAY` (–Ω–∞–ø—Ä–∏–º–µ—Ä, –¥–æ 10 —Å–µ–∫—É–Ω–¥)
2. –£–º–µ–Ω—å—à–∏—Ç—å `OZON_SCRAPER_BATCH_SIZE`
3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–µ—Ç –ª–∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –æ—Ç OZON

### –ü—Ä–æ–±–ª–µ–º–∞: –°–ª–∏—à–∫–æ–º –¥–æ–ª–≥–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ

**–†–µ—à–µ–Ω–∏–µ:**
1. –£–º–µ–Ω—å—à–∏—Ç—å `delay_seconds` (–æ—Å—Ç–æ—Ä–æ–∂–Ω–æ —Å rate limits!)
2. –£–≤–µ–ª–∏—á–∏—Ç—å `batch_size`
3. –ó–∞–ø—É—Å–∫–∞—Ç—å —Ä–µ–∂–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ä–∞–∑ –≤ 2 –¥–Ω—è)

---

## üìà Performance

### –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è

| –ê—Ä—Ç–∏–∫—É–ª–æ–≤ | Delay (—Å–µ–∫) | –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è |
|-----------|-------------|------------------|
| 100 | 5 | ~8 –º–∏–Ω—É—Ç |
| 500 | 5 | ~42 –º–∏–Ω—É—Ç—ã |
| 1000 | 5 | ~1.4 —á–∞—Å–∞ |
| 1000 | 2 | ~30 –º–∏–Ω—É—Ç |

**–§–æ—Ä–º—É–ª–∞:** `–≤—Ä–µ–º—è ‚âà (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_–∞—Ä—Ç–∏–∫—É–ª–æ–≤ √ó delay) / 60` –º–∏–Ω—É—Ç

---

## üîí –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å

### Best Practices

1. **Service Role Key:**
   - –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `SUPABASE_SERVICE_ROLE_KEY` (–Ω–µ anon key!)
   - –•—Ä–∞–Ω–∏—Ç–µ –≤ —Å–µ–∫—Ä–µ—Ç–∞—Ö (GitHub Secrets, Docker Secrets)

2. **Rate Limiting:**
   - –ù–µ —É–º–µ–Ω—å—à–∞–π—Ç–µ `delay` –Ω–∏–∂–µ 2 —Å–µ–∫—É–Ω–¥
   - –ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ 403 –æ—à–∏–±–æ–∫

3. **–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ:**
   - –í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ª–æ–≥–∏—Ä—É—é—Ç—Å—è –≤ –ë–î
   - –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –∞–ª–µ—Ä—Ç—ã –Ω–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏

---

## üìû Support

–ï—Å–ª–∏ –≤–æ–∑–Ω–∏–∫–ª–∏ –ø—Ä–æ–±–ª–µ–º—ã —Å cron jobs:
1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –≤ –ë–î (—Ç–∞–±–ª–∏—Ü–∞ `ozon_scraper_logs`)
2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ job –≤—Ä—É—á–Ω—É—é –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é OZON API

---

**–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ:** 2025-10-20

