"""
Cleanup Old Data - Cron Job

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ë–î –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞.

–ß—Ç–æ —É–¥–∞–ª—è–µ—Ç—Å—è:
- –ò—Å—Ç–æ—Ä–∏—è —Ü–µ–Ω —Å—Ç–∞—Ä—à–µ 30 –¥–Ω–µ–π (ozon_scraper_price_history)
- –õ–æ–≥–∏ —Å—Ç–∞—Ä—à–µ 90 –¥–Ω–µ–π (ozon_scraper_logs)
- –ò—Å—Ç–æ—Ä–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ —Å—Ç–∞—Ä—à–µ 30 –¥–Ω–µ–π (ozon_scraper_request_history)

–ó–∞–ø—É—Å–∫: –ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ (–≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ 04:00)

Usage:
    python -m cron_jobs.cleanup_old_data
"""

import asyncio
import sys
from datetime import datetime
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from loguru import logger
from database import get_supabase_client


class DataCleanupJob:
    """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ë–î"""
    
    def __init__(self):
        self.supabase = get_supabase_client()
        self.stats = {
            "start_time": None,
            "end_time": None,
            "price_history_deleted": 0,
            "logs_deleted": 0,
            "request_history_deleted": 0,
            "total_deleted": 0
        }
    
    def cleanup_price_history(self, days: int = 30) -> int:
        """
        –£–¥–∞–ª–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —Ü–µ–Ω —Å—Ç–∞—Ä—à–µ N –¥–Ω–µ–π
        
        Args:
            days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π
            
        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
        """
        try:
            # –í—ã–∑—ã–≤–∞–µ–º SQL —Ñ—É–Ω–∫—Ü–∏—é cleanup_old_price_history()
            result = self.supabase.rpc("cleanup_old_price_history").execute()
            deleted_count = result.data if result.data else 0
            
            logger.info(f"Deleted {deleted_count} old price history records (>{days} days)")
            return deleted_count
            
        except Exception as e:
            logger.error(f"Failed to cleanup price history: {e}")
            return 0
    
    def cleanup_logs(self, days: int = 90) -> int:
        """
        –£–¥–∞–ª–∏—Ç—å –ª–æ–≥–∏ —Å—Ç–∞—Ä—à–µ N –¥–Ω–µ–π
        
        Args:
            days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π
            
        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
        """
        try:
            # SQL: DELETE FROM ozon_scraper_logs WHERE timestamp < NOW() - INTERVAL '90 days'
            result = self.supabase.table("ozon_scraper_logs") \
                .delete() \
                .lt("timestamp", f"now() - interval '{days} days'") \
                .execute()
            
            deleted_count = len(result.data) if result.data else 0
            logger.info(f"Deleted {deleted_count} old log records (>{days} days)")
            return deleted_count
            
        except Exception as e:
            logger.error(f"Failed to cleanup logs: {e}")
            return 0
    
    def cleanup_request_history(self, days: int = 30) -> int:
        """
        –£–¥–∞–ª–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –∑–∞–ø—Ä–æ—Å–æ–≤ —Å—Ç–∞—Ä—à–µ N –¥–Ω–µ–π
        
        Args:
            days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π
            
        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
        """
        try:
            result = self.supabase.table("ozon_scraper_request_history") \
                .delete() \
                .lt("requested_at", f"now() - interval '{days} days'") \
                .execute()
            
            deleted_count = len(result.data) if result.data else 0
            logger.info(f"Deleted {deleted_count} old request history records (>{days} days)")
            return deleted_count
            
        except Exception as e:
            logger.error(f"Failed to cleanup request history: {e}")
            return 0
    
    def log_execution(self):
        """–õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"""
        try:
            log_entry = {
                "level": "INFO",
                "event_type": "cron_data_cleanup",
                "message": f"Data cleanup completed: {self.stats['total_deleted']} records deleted",
                "metadata": self.stats
            }
            
            self.supabase.table("ozon_scraper_logs") \
                .insert(log_entry) \
                .execute()
            
            logger.info("Cleanup execution logged to database")
            
        except Exception as e:
            logger.error(f"Failed to log cleanup execution: {e}")
    
    async def run(self):
        """–ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"""
        self.stats["start_time"] = datetime.now()
        
        logger.info("="*60)
        logger.info("üßπ Starting Data Cleanup Cron Job")
        logger.info("="*60)
        
        try:
            # –û—á–∏—Å—Ç–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ —Ü–µ–Ω (> 30 –¥–Ω–µ–π)
            self.stats["price_history_deleted"] = self.cleanup_price_history(days=30)
            
            # –û—á–∏—Å—Ç–∫–∞ –ª–æ–≥–æ–≤ (> 90 –¥–Ω–µ–π)
            self.stats["logs_deleted"] = self.cleanup_logs(days=90)
            
            # –û—á–∏—Å—Ç–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ (> 30 –¥–Ω–µ–π)
            self.stats["request_history_deleted"] = self.cleanup_request_history(days=30)
            
            # –ü–æ–¥—Å—á–µ—Ç –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
            self.stats["total_deleted"] = (
                self.stats["price_history_deleted"] +
                self.stats["logs_deleted"] +
                self.stats["request_history_deleted"]
            )
            
            self.stats["end_time"] = datetime.now()
            duration = (self.stats["end_time"] - self.stats["start_time"]).total_seconds()
            
            logger.info("="*60)
            logger.info("‚úÖ Data Cleanup Completed")
            logger.info("="*60)
            logger.info(f"Price history deleted: {self.stats['price_history_deleted']}")
            logger.info(f"Logs deleted: {self.stats['logs_deleted']}")
            logger.info(f"Request history deleted: {self.stats['request_history_deleted']}")
            logger.info(f"Total deleted: {self.stats['total_deleted']}")
            logger.info(f"Duration: {duration:.2f}s")
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            self.log_execution()
            
        except Exception as e:
            logger.critical(f"Data cleanup job failed: {e}")
            import traceback
            traceback.print_exc()


async def main():
    """Entry point"""
    job = DataCleanupJob()
    await job.run()


if __name__ == "__main__":
    asyncio.run(main())

