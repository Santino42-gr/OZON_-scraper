"""
Price Updater - Cron Job

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ü–µ–Ω —Ç–æ–≤–∞—Ä–æ–≤ OZON —á–µ—Ä–µ–∑ Parser Market API –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π.

–ó–∞–ø—É—Å–∫: 09:00 –∏ 15:00 (–Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç—Å—è)
–õ–æ–≥–∏–∫–∞:
- 09:00 - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∞—Ä—Ç–∏–∫—É–ª—ã —Å report_frequency IN ('once', 'twice')
- 15:00 - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ –∞—Ä—Ç–∏–∫—É–ª—ã —Å report_frequency = 'twice'
- –û–±–Ω–æ–≤–ª—è–µ—Ç —Ü–µ–Ω—ã –≤ —Ç–∞–±–ª–∏—Ü–µ ozon_scraper_articles
- –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –≤ ozon_scraper_price_history
- –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –≤ Telegram –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ —Ü–µ–Ω

Usage:
    python -m cron_jobs.price_updater

Environment Variables:
    SUPABASE_URL - URL Supabase –ø—Ä–æ–µ–∫—Ç–∞
    SUPABASE_SERVICE_ROLE_KEY - Service role –∫–ª—é—á –¥–ª—è –∑–∞–ø–∏—Å–∏ –≤ –ë–î
    PARSER_MARKET_API_KEY - API –∫–ª—é—á Parser Market
    TELEGRAM_BOT_TOKEN - –¢–æ–∫–µ–Ω Telegram –±–æ—Ç–∞ –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
    OZON_SCRAPER_BATCH_SIZE - –†–∞–∑–º–µ—Ä batch –¥–ª—è scraping (default: 10)
    OZON_SCRAPER_DELAY - –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∞—Ä—Ç–∏–∫—É–ª–∞–º–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (default: 2)
"""

import asyncio
import sys
import os
from datetime import datetime
from typing import List, Dict, Any, Optional
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º backend –≤ –ø—É—Ç—å
sys.path.insert(0, str(Path(__file__).parent.parent))

from loguru import logger
from database import get_supabase_client
from services.parser_market_client import ParserMarketClient
from services.telegram_notifier import get_telegram_notifier
from config import settings


class PriceUpdater:
    """
    –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ü–µ–Ω –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
    
    –ê–ª–≥–æ—Ä–∏—Ç–º:
    1. –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è (09:00 –∏–ª–∏ 15:00)
    2. –ü–æ–ª—É—á–∏—Ç—å –∞—Ä—Ç–∏–∫—É–ª—ã —Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–π —á–∞—Å—Ç–æ—Ç–æ–π –æ—Ç—á–µ—Ç–æ–≤
    3. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∞—Ä—Ç–∏–∫—É–ª–∞: –ø–æ–ª—É—á–∏—Ç—å –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ Parser Market
    4. –°—Ä–∞–≤–Ω–∏—Ç—å –Ω–æ–≤—ã–µ —Ü–µ–Ω—ã —Å–æ —Å—Ç–∞—Ä—ã–º–∏
    5. –û–±–Ω–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ –ë–î
    6. –û—Ç–ø—Ä–∞–≤–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –µ—Å–ª–∏ —Ü–µ–Ω—ã –∏–∑–º–µ–Ω–∏–ª–∏—Å—å
    """
    
    def __init__(self, batch_size: int = 10, delay_seconds: int = 2):
        """
        Args:
            batch_size: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞—Ä—Ç–∏–∫—É–ª–æ–≤ –≤ –æ–¥–Ω–æ–º batch
            delay_seconds: –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∞—Ä—Ç–∏–∫—É–ª–∞–º–∏ (–¥–ª—è rate limiting)
        """
        self.batch_size = batch_size
        self.delay_seconds = delay_seconds
        self.client = None
        self.supabase = get_supabase_client()
        self.notifier = None

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        self.stats = {
            "total_articles": 0,
            "successful": 0,
            "failed": 0,
            "notifications_sent": 0,
            "start_time": None,
            "end_time": None,
            "errors": []
        }
    
    def get_current_hour(self) -> int:
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–π —á–∞—Å (0-23)"""
        return datetime.now().hour
    
    def get_articles_by_frequency(self, hour: int) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –∞—Ä—Ç–∏–∫—É–ª—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤—Ä–µ–º–µ–Ω–∏
        
        Args:
            hour: –¢–µ–∫—É—â–∏–π —á–∞—Å (9 –¥–ª—è 09:00, 15 –¥–ª—è 15:00)
            
        Returns:
            –°–ø–∏—Å–æ–∫ –∞—Ä—Ç–∏–∫—É–ª–æ–≤ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ
        """
        try:
            query = self.supabase.table("ozon_scraper_articles") \
                .select("id, article_number, user_id, report_frequency, normal_price, ozon_card_price, name") \
                .eq("status", "active")
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —á–∞—Å—Ç–æ—Ç–µ –æ—Ç—á–µ—Ç–æ–≤
            if hour == 9:
                # 09:00 - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –∞—Ä—Ç–∏–∫—É–ª—ã —Å once –∏–ª–∏ twice
                query = query.in_("report_frequency", ["once", "twice"])
            elif hour == 15:
                # 15:00 - —Ç–æ–ª—å–∫–æ twice
                query = query.eq("report_frequency", "twice")
            else:
                # –î–ª—è –¥—Ä—É–≥–∏—Ö —á–∞—Å–æ–≤ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫
                logger.warning(f"Unexpected hour: {hour}. Expected 9 or 15.")
                return []
            
            response = query.execute()
            
            # –ü–æ–ª—É—á–∞–µ–º telegram_id –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º: –ø–æ–ª—É—á–∞–µ–º –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º
            user_ids = [article.get("user_id") for article in response.data if article.get("user_id")]
            unique_user_ids = list(set(user_ids))
            
            # –ü–æ–ª—É—á–∞–µ–º telegram_id –¥–ª—è –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
            users_map = {}
            if unique_user_ids:
                users_response = self.supabase.table("ozon_scraper_users") \
                    .select("id, telegram_id") \
                    .in_("id", unique_user_ids) \
                    .execute()
                
                for user in users_response.data:
                    users_map[user["id"]] = user.get("telegram_id")
            
            # –î–æ–±–∞–≤–ª—è–µ–º telegram_id –∫ –∞—Ä—Ç–∏–∫—É–ª–∞–º
            articles_with_users = []
            for article in response.data:
                user_id = article.get("user_id")
                if user_id and user_id in users_map:
                    article["telegram_id"] = users_map[user_id]
                    articles_with_users.append(article)
            
            logger.info(f"Found {len(articles_with_users)} articles to process for hour {hour}")
            return articles_with_users
            
        except Exception as e:
            logger.error(f"Failed to fetch articles from DB: {e}")
            return []
    
    async def initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤"""
        self.client = ParserMarketClient(
            api_key=settings.PARSER_MARKET_API_KEY,
            region=settings.PARSER_MARKET_REGION,
            timeout=settings.PARSER_MARKET_TIMEOUT,
            poll_interval=settings.PARSER_MARKET_POLL_INTERVAL
        )
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º notifier
        bot_token = os.getenv("TELEGRAM_BOT_TOKEN")
        if not bot_token:
            logger.warning("TELEGRAM_BOT_TOKEN not set, notifications will be disabled")
        else:
            self.notifier = get_telegram_notifier(bot_token=bot_token)
        
        logger.info("Clients initialized for price updater")

    async def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        if self.client:
            await self.client.close()
        logger.info("Resources cleaned up")
    
    async def update_article_price(
        self,
        article: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """
        –û–±–Ω–æ–≤–∏—Ç—å —Ü–µ–Ω—É –∞—Ä—Ç–∏–∫—É–ª–∞ –∏ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏
        
        Args:
            article: –î–∞–Ω–Ω—ã–µ –∞—Ä—Ç–∏–∫—É–ª–∞ –∏–∑ –ë–î
            
        Returns:
            –ù–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –æ —Ü–µ–Ω–∞—Ö –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        try:
            article_number = article["article_number"]
            article_id = article["id"]
            
            # –ü–æ–ª—É—á–∞–µ–º –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ Parser Market
            product_info = await self.client.parse_sync(article_number)

            if not product_info:
                logger.warning(f"No data found for article: {article_number}")
                return None

            # –°—Ç–∞—Ä—ã–µ —Ü–µ–Ω—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            old_prices = {
                "normal_price": article.get("normal_price"),
                "ozon_card_price": article.get("ozon_card_price")
            }
            
            # –ù–æ–≤—ã–µ —Ü–µ–Ω—ã
            new_prices = {
                "normal_price": product_info.normal_price,
                "ozon_card_price": product_info.ozon_card_price
            }
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Ç–∞–±–ª–∏—Ü–µ articles
            update_data = {
                "price": product_info.price,
                "normal_price": product_info.normal_price,
                "ozon_card_price": product_info.ozon_card_price,
                "old_price": product_info.old_price,
                "name": product_info.name,
                "rating": product_info.rating,
                "reviews_count": product_info.reviews_count,
                "available": product_info.available,
                "last_check": datetime.now().isoformat(),
                "price_updated_at": datetime.now().isoformat(),
                "updated_at": datetime.now().isoformat()
            }
            
            self.supabase.table("ozon_scraper_articles") \
                .update(update_data) \
                .eq("id", article_id) \
                .execute()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é —Ü–µ–Ω
            price_history_data = {
                "article_number": article_number,
                "price": product_info.price,
                "normal_price": product_info.normal_price,
                "ozon_card_price": product_info.ozon_card_price,
                "old_price": product_info.old_price,
                "product_available": product_info.available,
                "rating": product_info.rating,
                "reviews_count": product_info.reviews_count,
                "source": "parser_market_api",
                "scraping_success": True,
                "scraping_duration_ms": product_info.fetch_time_ms,
                "price_date": datetime.now().isoformat()
            }
            
            self.supabase.table("ozon_scraper_price_history") \
                .insert(price_history_data) \
                .execute()
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –µ—Å–ª–∏ —Ü–µ–Ω—ã –∏–∑–º–µ–Ω–∏–ª–∏—Å—å
            if self.notifier and article.get("telegram_id"):
                telegram_id = article["telegram_id"]
                article_name = article.get("name") or product_info.name
                
                try:
                    success = await self.notifier.send_price_update_notification(
                        telegram_id=telegram_id,
                        article_number=article_number,
                        article_name=article_name,
                        old_prices=old_prices,
                        new_prices=new_prices
                    )
                    
                    if success:
                        self.stats["notifications_sent"] += 1
                except Exception as e:
                    logger.warning(f"Failed to send notification for {article_number}: {e}")
            
            logger.info(
                f"‚úÖ Updated {article_number}: "
                f"normal={new_prices['normal_price']}, "
                f"card={new_prices['ozon_card_price']}"
            )
            
            return {
                "article_number": article_number,
                "old_prices": old_prices,
                "new_prices": new_prices
            }

        except Exception as e:
            logger.error(f"‚ùå Failed to update article {article.get('article_number', 'unknown')}: {e}")
            self.stats["errors"].append({
                "article": article.get("article_number", "unknown"),
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            })
            return None
    
    async def process_batch(self, articles: List[Dict[str, Any]]):
        """
        –û–±—Ä–∞–±–æ—Ç–∞—Ç—å batch –∞—Ä—Ç–∏–∫—É–ª–æ–≤
        
        Args:
            articles: –°–ø–∏—Å–æ–∫ –∞—Ä—Ç–∏–∫—É–ª–æ–≤ —Å –¥–∞–Ω–Ω—ã–º–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        """
        for article in articles:
            result = await self.update_article_price(article)
            
            if result:
                self.stats["successful"] += 1
            else:
                self.stats["failed"] += 1
            
            # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ (rate limiting)
            await asyncio.sleep(self.delay_seconds)
    
    async def run(self):
        """
        –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥: –∑–∞–ø—É—Å–∫ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ü–µ–Ω
        """
        self.stats["start_time"] = datetime.now()
        current_hour = self.get_current_hour()
        
        logger.info("="*60)
        logger.info(f"üöÄ Starting Price Updater Cron Job (Hour: {current_hour:02d}:00)")
        logger.info("="*60)
        
        try:
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
            await self.initialize()
            
            # –ü–æ–ª—É—á–∏—Ç—å –∞—Ä—Ç–∏–∫—É–ª—ã –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏
            articles = self.get_articles_by_frequency(current_hour)
            self.stats["total_articles"] = len(articles)
            
            if not articles:
                logger.warning(f"No articles found to process for hour {current_hour}")
                return
            
            logger.info(f"Processing {len(articles)} articles in batches of {self.batch_size}")
            
            # –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∞—Ä—Ç–∏–∫—É–ª—ã batch-–∞–º–∏
            for i in range(0, len(articles), self.batch_size):
                batch = articles[i:i + self.batch_size]
                batch_num = (i // self.batch_size) + 1
                total_batches = (len(articles) + self.batch_size - 1) // self.batch_size
                
                logger.info(f"Processing batch {batch_num}/{total_batches} ({len(batch)} articles)")
                await self.process_batch(batch)
            
            # –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è
            self.stats["end_time"] = datetime.now()
            duration = (self.stats["end_time"] - self.stats["start_time"]).total_seconds()
            
            logger.info("="*60)
            logger.info("‚úÖ Price Updater Completed")
            logger.info("="*60)
            logger.info(f"Total articles: {self.stats['total_articles']}")
            logger.info(f"Successful: {self.stats['successful']}")
            logger.info(f"Failed: {self.stats['failed']}")
            logger.info(f"Notifications sent: {self.stats['notifications_sent']}")
            logger.info(f"Duration: {duration:.2f}s")
            logger.info(f"Success rate: {(self.stats['successful'] / max(self.stats['total_articles'], 1) * 100):.1f}%")
            
            if self.stats["errors"]:
                logger.warning(f"Errors encountered: {len(self.stats['errors'])}")
                for error in self.stats["errors"][:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 –æ—à–∏–±–æ–∫
                    logger.warning(f"  - {error['article']}: {error['error']}")
            
            # –õ–æ–≥–∏—Ä—É–µ–º –≤ –ë–î
            self.log_cron_execution()
            
        except Exception as e:
            logger.critical(f"Cron job failed with critical error: {e}")
            import traceback
            traceback.print_exc()
            
        finally:
            await self.cleanup()
    
    def log_cron_execution(self):
        """–õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è cron job –≤ –ë–î"""
        try:
            log_entry = {
                "level": "INFO" if self.stats["failed"] == 0 else "WARNING",
                "event_type": "cron_price_update",
                "message": f"Price update completed: {self.stats['successful']}/{self.stats['total_articles']} successful, {self.stats['notifications_sent']} notifications sent",
                "metadata": {
                    "stats": self.stats,
                    "batch_size": self.batch_size,
                    "delay_seconds": self.delay_seconds,
                    "hour": self.get_current_hour()
                }
            }
            
            self.supabase.table("ozon_scraper_logs") \
                .insert(log_entry) \
                .execute()
            
            logger.info("Cron execution logged to database")
            
        except Exception as e:
            logger.error(f"Failed to log cron execution: {e}")


async def main():
    """
    Entry point –¥–ª—è cron job
    """
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–∑ environment variables
    batch_size = int(os.getenv("OZON_SCRAPER_BATCH_SIZE", "10"))
    delay = int(os.getenv("OZON_SCRAPER_DELAY", "5"))
    
    updater = PriceUpdater(batch_size=batch_size, delay_seconds=delay)
    await updater.run()


if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫ cron job
    asyncio.run(main())

